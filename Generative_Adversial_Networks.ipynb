{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO4jcSfckNnUWhi1KZIULSf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alex1grrt/Machine-Learning-Projects/blob/main/Generative_Adversial_Networks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KUNVVevSMsGb"
      },
      "outputs": [],
      "source": [
        "\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Input, Dense, LeakyReLU, Dropout, BatchNormalization\n",
        "from tensorflow.keras.models import Model \n",
        "from tensorflow.keras.optimizers import SGD, Adam\n"
      ],
      "metadata": {
        "id": "QyUNJ1MKTeOD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt \n",
        "import sys, os "
      ],
      "metadata": {
        "id": "A4Eeni0PYtv7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "x_train, y_train = x_train / 255.0 * 2 - 1, y_train / 255.0 * 2 -1 \n",
        "print('x_train.shape:', x_train.shape)\n"
      ],
      "metadata": {
        "id": "atQwbfr-Ytyw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "N, H, W = x_train.shape\n",
        "D = H * W\n",
        "x_train = x_train.reshape(-1, D)\n",
        "x_test = x_test.reshape(-1, D)"
      ],
      "metadata": {
        "id": "aUgbKgHhYt1c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latent_dim = 100"
      ],
      "metadata": {
        "id": "i--49BBEZoun"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_generator(latent_dim):\n",
        "  i = Input(shape=(latent_dim,))\n",
        "  x = Dense(256, activation=LeakyReLU(alpha=0.2))(i)\n",
        "  x = BatchNormalization(momentum=0.8)(x)\n",
        "  x = Dense(512, activation=LeakyReLU(alpha=0.2))(x)\n",
        "  x = BatchNormalization(momentum=0.8)(x)\n",
        "  x = Dense(1024, activation=LeakyReLU(alpha=0.2))(x)\n",
        "  x = BatchNormalization(momentum=0.8)(x)\n",
        "  x = Dense(D, activation='tanh')(x)\n",
        "\n",
        "  model = Model(i, x)\n",
        "  return model"
      ],
      "metadata": {
        "id": "joqm3AOmZoxo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_discriminator(img_size):\n",
        "  i = Input(shape=(img_size,))\n",
        "  x = Dense(512, activation=LeakyReLU(alpha=0.2))(i)\n",
        "  x = Dense(256, activation=LeakyReLU(alpha=0.2))(x)\n",
        "  x = Dense(1, activation='sigmoid')(x)\n",
        "  model = Model(i, x)\n",
        "  return model"
      ],
      "metadata": {
        "id": "Ai3viCQ1Zo0Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "discriminator = build_discriminator(D)\n",
        "discriminator.compile(\n",
        "    loss='binary_crossentropy',\n",
        "    optimizer=Adam(0.0002, 0.5),\n",
        "    metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "OIc5-j1SZo3A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generator = build_generator(latent_dim)\n",
        "\n",
        "z = Input(shape=(latent_dim,))\n",
        "\n",
        "img = generator(z)\n",
        "\n",
        "discriminator.trainable = False\n",
        "\n",
        "fake_pred = discriminator(img)\n",
        "\n",
        "combined_model = Model(z, fake_pred)\n",
        "\n",
        "combined_model.compile(loss='binary_crossentropy',\n",
        "                       optimizer=Adam(0.0002, 0.5))"
      ],
      "metadata": {
        "id": "4fv6jY60Zo50"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "epochs = 300000\n",
        "sample_period = 200"
      ],
      "metadata": {
        "id": "YoYiB9m9cAUy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ones= np.ones(batch_size)\n",
        "zeros = np.zeros(batch_size)"
      ],
      "metadata": {
        "id": "ybcJ8hhvcAXt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d_losses = []\n",
        "g_losses = []"
      ],
      "metadata": {
        "id": "e9avCycxcAax"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.exists('gan_images'):\n",
        "  os.makedirs('gan_images')"
      ],
      "metadata": {
        "id": "lvlMs3c9cR_y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sample_images(epoch):\n",
        "  rows, cols = 5, 5\n",
        "  noise = np.random.randn(rows * cols, latent_dim)\n",
        "  imgs = generator.predict(noise)\n",
        "\n",
        "  imgs = 0.5 * imgs + 0.5\n",
        "\n",
        "  fig, axs = plt.subplots(rows, cols)\n",
        "  idx = 0\n",
        "  for i in range(rows):\n",
        "    for j in range(cols):\n",
        "      axs[i,j].imshow(imgs[idx].reshape(H, W), cmap='gray')\n",
        "      axs[i,j].axis('off')\n",
        "      idx += 1\n",
        "    fig.savefig('gan_images/%d.png' % epoch)\n",
        "    plt.close()"
      ],
      "metadata": {
        "id": "hsbLQz59cSCl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(epochs):\n",
        "  idx = np.random.randint(0, x_train.shape[0], batch_size)\n",
        "  real_imgs = x_train[idx]\n",
        "  noise = np.random.randn(batch_size, latent_dim)\n",
        "  fake_imgs = generator.predict(noise)\n",
        "  d_loss_real, d_acc_real = discriminator.train_on_batch(real_imgs, ones)\n",
        "  d_loss_fake, d_acc_fake = discriminator.train_on_batch(fake_imgs, zeros)\n",
        "  d_loss = 0.5 * (d_loss_real + d_loss_fake)\n",
        "  d_acc = 0.5 * (d_acc_real + d_acc_fake)\n",
        "  noise = np.random.randn(batch_size, latent_dim)\n",
        "  g_loss = combined_model.train_on_batch(noise, ones)\n",
        "  d_losses.append(d_loss)\n",
        "  g_losses.append(g_loss)\n",
        "  if epoch % 100 == 0:\n",
        "    print(f'epoch: {epoch+1}/{epochs}, d_loss: {d_loss:.2f}, d_acc: {d_acc:.2f}, g_loss: {g_loss:.2f}')\n",
        "\n",
        "  if epoch % sample_period == 0:\n",
        "    sample_images(epoch)\n"
      ],
      "metadata": {
        "id": "vhzPO2bMcSFL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(g_losses, label='g_losses')\n",
        "plt.plot(d_losses, label='d_losses')\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "MuP6WYEIcSH3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls gan_images #erstellte Bilder"
      ],
      "metadata": {
        "id": "h6tvPY6-cSKv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from skimage.io import imread \n",
        "a = imread('gan_images/0.png')  #Bei 0 Trainingsabläufen\n",
        "plt.imshow(a)"
      ],
      "metadata": {
        "id": "wQEVV9mFcSNe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = imread('gan_images/1000.png')     #Bei 1000 Trainingsabläufen\n",
        "plt.imshow(a)"
      ],
      "metadata": {
        "id": "dtaLGLFzgVL7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = imread('gan_images/5000.png')     #Bei 5000 Trainingsabläufen\n",
        "plt.imshow(a)"
      ],
      "metadata": {
        "id": "pR0dyo4hgVO7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = imread('gan_images/10000.png')      #Bei 10000 Trainingsabläufen\n",
        "plt.imshow(a)"
      ],
      "metadata": {
        "id": "RHkWodR_gVRs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = imread('gan_images/20000.png')      #Bei 20000 Trainingsabläufen\n",
        "plt.imshow(a)"
      ],
      "metadata": {
        "id": "MJm1VF-rguNn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = imread('gan_images/29800.png')      #Bei 29800 Trainingsabläufen\n",
        "plt.imshow(a)"
      ],
      "metadata": {
        "id": "BXvjGqLqguUa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}